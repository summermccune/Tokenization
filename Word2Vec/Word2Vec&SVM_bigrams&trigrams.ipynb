{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt6M9LJuRvw3s/Pf4ngoJq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/summermccune/Tokenization-Testing-for-Malware-Data/blob/main/Word2Vec/Word2Vec%26SVM_bigrams%26trigrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcLhu_5gyQfq",
        "outputId": "b8079aa4-3f3b-4087-a51f-af385f29fd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.utils import simple_preprocess\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import glob\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import trigrams\n",
        "from nltk.util import bigrams\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "C5sfpudS05f-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea5061a-0e65-41b2-a2b2-bf1c43f92894"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently splitting into bigrams and trigrams by each sample, not within each sample. So, one sample would be split into trigrams and the other into bigrams and so on until it goes through all the samples"
      ],
      "metadata": {
        "id": "zRP4ANdM1f1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files(malwarefolder, malwareType):\n",
        "  count = 0\n",
        "  for sample in malwarefolder:\n",
        "    count += 1\n",
        "    with open(sample, 'r') as f:\n",
        "      data = f.read().split()\n",
        "      if count % 2 == 0:\n",
        "        #make opcodes into trigrams\n",
        "        trigrms = list(trigrams(data))\n",
        "        #make the trigrams each their own string\n",
        "        trigrms = [f\"{first} {second} {third}\" for first, second, third in trigrms]\n",
        "        data = trigrms\n",
        "      else:\n",
        "        #make opcodes into bigrams\n",
        "        bigrms = list(bigrams(data))\n",
        "        #make the bigrams each their own string\n",
        "        bigrms = [f\"{first} {second}\" for first, second in bigrms]\n",
        "        data = bigrms\n",
        "    #append sample to opcodes list in df\n",
        "    df.loc[len(df)] = [data, malwareType]"
      ],
      "metadata": {
        "id": "m4VYX1UeL6qb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataframe for samples and label\n",
        "df = pd.DataFrame(columns = ['opcodes','label'])\n",
        "\n",
        "#specify paths for each malware\n",
        "winwebsec = glob.glob(\"/content/drive/MyDrive/Data/malware2/winwebsec/*.txt\")\n",
        "zbot = glob.glob(\"/content/drive/MyDrive/Data/malware2/zbot/*.txt\")\n",
        "zeroaccess = glob.glob(\"/content/drive/MyDrive/Data/malware2/zeroaccess/*.txt\")\n",
        "\n",
        "#read files\n",
        "read_files(winwebsec, 0)\n",
        "read_files(zbot, 1)\n",
        "read_files(zeroaccess, 2)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7QNq5mWV7KsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec\n",
        "model = Word2Vec(df['opcodes'], min_count=1, vector_size=100)"
      ],
      "metadata": {
        "id": "3ObhJWWV42tN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "X = np.array([np.mean([model.wv[word] for word in text if word in model.wv]\n",
        "                        , axis=0) for text in df['opcodes']])\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "svm = SVC(kernel='rbf')\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "#accuracy and conf matrix\n",
        "print(\"Accuracy:\", np.mean(y_pred == y_test))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "IEyA6zyPkoS-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}