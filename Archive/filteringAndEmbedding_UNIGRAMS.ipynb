{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2igberwboySEOqnpJlp+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/summermccune/Tokenization-Testing-for-Malware-Data/blob/main/Word2Vec/filteringAndEmbedding_UNIGRAMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKPIEN_GXZ8S"
      },
      "outputs": [],
      "source": [
        "!pip install \"scipy==1.11.0\"#change this line?\n",
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install glob\n",
        "!pip install nltk\n",
        "!pip install csv\n",
        "!pip install collections\n",
        "!pip install re\n",
        "!pip install gc\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "import csv\n",
        "from collections import Counter\n",
        "import re\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3CIU2TbWKlM9"
      },
      "outputs": [],
      "source": [
        "def count(df, c):\n",
        "  for row in df['Opcodes']:\n",
        "     data = row.split()\n",
        "     c.update(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IjpKkjrGgDWQ"
      },
      "outputs": [],
      "source": [
        "def removeNonVocab(vocab, series):\n",
        "  rows = []\n",
        "  vocab_str = '|'.join(vocab)\n",
        "  pattern = '\\\\b((?!\\\\b( |' + vocab_str + ')\\\\b).)*\\\\b'\n",
        "  for row in series:\n",
        "    row = re.sub(pattern, '', row)\n",
        "    row = re.sub(' +', ' ', row)\n",
        "    rows.append(row)\n",
        "  return rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read in the data\n",
        "FakeRean = pd.read_csv('FakeRean.csv')\n",
        "OnLineGames = pd.read_csv('OnLineGames.csv')\n",
        "Vobfus = pd.read_csv('Vobfus.csv')\n",
        "Winwebsec = pd.read_csv('Winwebsec.csv')\n",
        "\n",
        "FakeRean_df = pd.DataFrame(FakeRean)\n",
        "OnLineGames_df = pd.DataFrame(OnLineGames)\n",
        "Vobfus_df = pd.DataFrame(Vobfus)\n",
        "Winwebsec_df = pd.DataFrame(Winwebsec)\n",
        "\n",
        "#drop first column\n",
        "FakeRean_df = FakeRean_df.iloc[:, 1:]\n",
        "OnLineGames_df = OnLineGames_df.iloc[:, 1:]\n",
        "Vobfus_df = Vobfus_df.iloc[:, 1:]\n",
        "Winwebsec_df = Winwebsec_df.iloc[:, 1:]"
      ],
      "metadata": {
        "id": "NXB9CVMNYSHg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting opcodes for data cleaning\n",
        "countTotal = Counter()\n",
        "count(FakeRean_df, countTotal)\n",
        "count(OnLineGames_df,countTotal)\n",
        "count(Vobfus_df,countTotal)\n",
        "count(Winwebsec_df,countTotal)"
      ],
      "metadata": {
        "id": "KlAi81zmYk0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list for most common opcodes\n",
        "total_count = countTotal.most_common(31)\n",
        "countList = [x[0] for x in total_count]\n",
        "print(countList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h57NfxNTZqh1",
        "outputId": "0ede668b-ffa5-4124-a476-6dea18b5681e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['add', 'mov', 'push', 'pop', 'inc', 'xchg', 'call', 'or', 'dec', 'cmp', 'xor', 'sub', 'and', 'adc', 'sbb', 'lea', 'test', 'out', 'in', 'jmp', 'movl', 'int3', 'ret', 'imul', 'je', 'nop', 'lods', 'stos', 'scas', 'lret', 'jne']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding cleaned data to new dataframe\n",
        "rows = []\n",
        "\n",
        "#0 for FakeRean\n",
        "FakeRean_rows = removeNonVocab(countList, FakeRean_df['Opcodes'])\n",
        "for row in FakeRean_rows:\n",
        "  row = row.split()\n",
        "  rows.append((tuple(row), 0))\n",
        "\n",
        "#1 for OnLineGames\n",
        "OnLineGames_rows = removeNonVocab(countList, OnLineGames_df['Opcodes'])\n",
        "for row in OnLineGames_rows:\n",
        "  row = row.split()\n",
        "  rows.append((tuple(row), 1))\n",
        "\n",
        "#2 for Vobfus\n",
        "Vobfus_rows = removeNonVocab(countList, Vobfus_df['Opcodes'])\n",
        "for row in Vobfus_rows:\n",
        "  row = row.split()\n",
        "  rows.append((tuple(row), 2))\n",
        "\n",
        "#3 for Winwebsec\n",
        "Winwebsec_rows = removeNonVocab(countList, Winwebsec_df['Opcodes'])\n",
        "for row in Winwebsec_rows:\n",
        "  row = row.split()\n",
        "  rows.append((tuple(row), 3))\n"
      ],
      "metadata": {
        "id": "kntLSqR5ZXzV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make csv of most common opcodes and their count\n",
        "df = pd.DataFrame(total_count, columns=['Opcodes', 'Count'])\n",
        "df.to_csv('MostCommonOpcodes.csv', index=False)"
      ],
      "metadata": {
        "id": "-YdW16TEfJkU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn rows tuple into df\n",
        "df = pd.DataFrame(rows, columns=['Opcodes', 'MalwareType'])\n",
        "\n",
        "#cleaned rows as csv\n",
        "df.to_csv('UnigramFilteredOpcodes.csv', index=False)"
      ],
      "metadata": {
        "id": "TV761pBDcGRw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec N = 100, W = 30\n",
        "model = Word2Vec(df['Opcodes'], min_count=1, vector_size=100, window=30)\n",
        "embeddings = np.array([np.mean([model.wv[word] for word in text if word in model.wv], axis=0) for text in df['Opcodes']])\n",
        "np.save('ALL_embeddings.npy', embeddings)\n",
        "\n",
        "#word2vec N = 31, W = 10\n",
        "model = Word2Vec(df['Opcodes'], min_count=1, vector_size=31, window=10)\n",
        "embeddings = np.array([np.mean([model.wv[word] for word in text if word in model.wv], axis=0) for text in df['Opcodes']])\n",
        "np.save('SVM_embeddings.npy', embeddings)"
      ],
      "metadata": {
        "id": "6anxSjm0cKZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Reading from the Created CSV"
      ],
      "metadata": {
        "id": "F2XJlB7srqoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('UnigramFilteredOpcodes.csv')\n",
        "#turn to df\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmtHkJaGjz2o",
        "outputId": "804ab4a1-112e-4411-9b16-f05fab1576ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Opcodes  MalwareType\n",
            "0  ('add', 'je', 'je', 'push', 'push', 'add', 'ad...            0\n",
            "1  ('push', 'mov', 'push', 'push', 'mov', 'xor', ...            0\n",
            "2  ('call', 'mov', 'pop', 'pop', 'pop', 'ret', 'i...            0\n",
            "3  ('add', 'in', 'add', 'push', 'call', 'pop', 'r...            0\n",
            "4  ('mov', 'push', 'push', 'push', 'mov', 'mov', ...            0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_YHczT6rYS2",
        "outputId": "ee012223-26d5-45c2-d282-56df7271293c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Opcodes  MalwareType\n",
            "3995  ('push', 'mov', 'sub', 'push', 'push', 'push',...            3\n",
            "3996  ('push', 'mov', 'sub', 'push', 'push', 'push',...            3\n",
            "3997  ('int3', 'int3', 'int3', 'int3', 'int3', 'int3...            3\n",
            "3998  ('push', 'mov', 'mov', 'int3', 'int3', 'int3',...            3\n",
            "3999  ('or', 'xchg', 'call', 'inc', 'mov', 'or', 'po...            3\n"
          ]
        }
      ]
    }
  ]
}
